{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8282a088-298f-4d8b-ba24-5789aa440bf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch: 2.5.1+cu121\n",
      "CUDA available: True\n",
      "nnU-Net v2 imported successfully!\n",
      "nnunetv2 location: C:\\Users\\User\\anaconda3\\envs\\nnunet_new\\Lib\\site-packages\\nnunetv2\\__init__.py\n"
     ]
    }
   ],
   "source": [
    "import torch, nnunetv2\n",
    "print(\"Torch:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"nnU-Net v2 imported successfully!\")\n",
    "\n",
    "# Test that you can access nnunetv2 modules\n",
    "print(\"nnunetv2 location:\", nnunetv2.__file__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63eaeca7-0cf7-4026-9ccd-24e5e552a7d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch: 2.5.1+cu121 | CUDA: 12.1\n",
      "nnU-Net v2: imported successfully!\n",
      "nnU-Net directories created at: D:/nnunet_with_classification/data\n"
     ]
    }
   ],
   "source": [
    "import os, nnunetv2, torch\n",
    "\n",
    "# Work directories - updated for your local setup\n",
    "BASE = \"D:/nnunet_with_classification/data\"\n",
    "RAW  = f\"{BASE}/nnUNet_raw\"\n",
    "PREP = f\"{BASE}/nnUNet_preprocessed\"\n",
    "RES  = f\"{BASE}/nnUNet_results\"\n",
    "\n",
    "# Create nnU-Net directories\n",
    "os.makedirs(RAW, exist_ok=True)\n",
    "os.makedirs(PREP, exist_ok=True)\n",
    "os.makedirs(RES, exist_ok=True)\n",
    "\n",
    "# Set environment variables\n",
    "os.environ[\"nnUNet_raw\"] = RAW\n",
    "os.environ[\"nnUNet_preprocessed\"] = PREP\n",
    "os.environ[\"nnUNet_results\"] = RES\n",
    "\n",
    "print(\"Torch:\", torch.__version__, \"| CUDA:\", torch.version.cuda)\n",
    "print(\"nnU-Net v2: imported successfully!\")\n",
    "print(f\"nnU-Net directories created at: {BASE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3405a90-353b-41cf-99f6-4659c37083b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imagesTr: 288\n",
      "labelsTr: 288\n",
      "imagesTs: 72\n",
      "Mapped classification labels: 288\n",
      "Wrote dataset.json, splits_final.json, classification_labels.csv\n"
     ]
    }
   ],
   "source": [
    "import os, glob, pathlib, shutil, re, json, csv\n",
    "\n",
    "# >>>>>>>>>>>> UPDATE THIS PATH <<<<<<<<<<<<\n",
    "SRC = \"D:/nnunet_with_classification/data\"\n",
    "\n",
    "DSID = 777\n",
    "DSNAME = f\"Dataset{DSID:03d}_M31Quiz\"\n",
    "RAW  = os.environ[\"nnUNet_raw\"]\n",
    "PREP = os.environ[\"nnUNet_preprocessed\"]\n",
    "DSROOT = f\"{RAW}/{DSNAME}\"\n",
    "imgTr = f\"{DSROOT}/imagesTr\"; lblTr = f\"{DSROOT}/labelsTr\"; imgTs = f\"{DSROOT}/imagesTs\"\n",
    "for d in (imgTr, lblTr, imgTs): os.makedirs(d, exist_ok=True)\n",
    "\n",
    "def stem(p): return pathlib.Path(p).name.replace(\".nii.gz\",\"\")\n",
    "sub_regex = re.compile(r\"subtype\\s*([012])\", re.IGNORECASE)\n",
    "\n",
    "def find_split(name):\n",
    "    # case-insensitive split folder lookup\n",
    "    for cand in os.listdir(SRC):\n",
    "        if cand.lower() == name:\n",
    "            p = os.path.join(SRC, cand)\n",
    "            if os.path.isdir(p): return p\n",
    "    return None\n",
    "\n",
    "train_dir = find_split(\"train\")\n",
    "val_dir   = find_split(\"validation\")\n",
    "test_dir  = find_split(\"test\")\n",
    "assert train_dir and val_dir and test_dir, f\"Could not find train/validation/test under {SRC}\"\n",
    "\n",
    "def ingest_split(split_dir, cls_map):\n",
    "    imgs = glob.glob(os.path.join(split_dir, \"**\", \"*_0000.nii.gz\"), recursive=True)\n",
    "    used = 0\n",
    "    for img in sorted(imgs):\n",
    "        case = stem(img).replace(\"_0000\",\"\")\n",
    "        msk  = img.replace(\"_0000.nii.gz\",\".nii.gz\")\n",
    "        if not os.path.exists(msk):\n",
    "            continue\n",
    "        shutil.copy(img, f\"{imgTr}/{case}_0000.nii.gz\")\n",
    "        shutil.copy(msk, f\"{lblTr}/{case}.nii.gz\")\n",
    "        used += 1\n",
    "        # infer subtype from folder names (expects 'subtype0/1/2')\n",
    "        sub_idx = None\n",
    "        for part in pathlib.Path(img).parts:\n",
    "            m = sub_regex.search(part)\n",
    "            if m:\n",
    "                sub_idx = int(m.group(1)); break\n",
    "        if sub_idx is not None:\n",
    "            cls_map[case] = sub_idx\n",
    "    return used\n",
    "\n",
    "cls_map = {}\n",
    "n_tr = ingest_split(train_dir, cls_map)\n",
    "n_va = ingest_split(val_dir,   cls_map)\n",
    "\n",
    "# test images\n",
    "for img in sorted(glob.glob(os.path.join(test_dir, \"**\", \"*_0000.nii.gz\"), recursive=True)):\n",
    "    case = stem(img).replace(\"_0000\",\"\")\n",
    "    shutil.copy(img, f\"{imgTs}/{case}_0000.nii.gz\")\n",
    "\n",
    "print(\"imagesTr:\", len(glob.glob(f\"{imgTr}/*_0000.nii.gz\")))\n",
    "print(\"labelsTr:\", len(glob.glob(f\"{lblTr}/*.nii.gz\")))\n",
    "print(\"imagesTs:\", len(glob.glob(f\"{imgTs}/*_0000.nii.gz\")))\n",
    "print(\"Mapped classification labels:\", len(cls_map))\n",
    "\n",
    "# dataset.json\n",
    "dataset_json = {\n",
    "  \"name\": DSNAME,\n",
    "  \"tensorImageSize\": \"3D\",\n",
    "  \"modality\": {\"0\": \"CT\"},\n",
    "  \"labels\": {\"background\": 0, \"pancreas\": 1, \"lesion\": 2},\n",
    "  \"numTraining\": len(glob.glob(f\"{lblTr}/*.nii.gz\")),\n",
    "  \"numTest\": len(glob.glob(f\"{imgTs}/*_0000.nii.gz\")),\n",
    "  \"training\": [{\"image\": f\"./imagesTr/{stem(i)}.nii.gz\",\n",
    "                \"label\": f\"./labelsTr/{stem(i).replace('_0000','')}.nii.gz\"}\n",
    "               for i in sorted(glob.glob(f\"{imgTr}/*_0000.nii.gz\"))],\n",
    "  \"test\": [f\"./imagesTs/{stem(i)}.nii.gz\" for i in sorted(glob.glob(f\"{imgTs}/*_0000.nii.gz\"))]\n",
    "}\n",
    "os.makedirs(DSROOT, exist_ok=True)\n",
    "with open(f\"{DSROOT}/dataset.json\",\"w\") as f: json.dump(dataset_json, f, indent=2)\n",
    "\n",
    "# splits_final.json (use original validation as nnU-Net val)\n",
    "val_cases = {stem(p).replace(\"_0000\",\"\") for p in glob.glob(os.path.join(val_dir, \"**\", \"*_0000.nii.gz\"), recursive=True)}\n",
    "all_cases = sorted([stem(p).replace(\"_0000\",\"\") for p in glob.glob(f\"{imgTr}/*_0000.nii.gz\")])\n",
    "train_cases = [c for c in all_cases if c not in val_cases]\n",
    "spdir = f\"{PREP}/{DSNAME}\"\n",
    "os.makedirs(spdir, exist_ok=True)\n",
    "with open(f\"{spdir}/splits_final.json\",\"w\") as f:\n",
    "    json.dump([{\"train\": train_cases, \"val\": sorted(list(val_cases))}], f, indent=2)\n",
    "\n",
    "# classification_labels.csv\n",
    "csv_path = f\"{spdir}/classification_labels.csv\"\n",
    "with open(csv_path, \"w\", newline=\"\") as f:\n",
    "    w = csv.writer(f)\n",
    "    for c in all_cases:\n",
    "        if c in cls_map:\n",
    "            w.writerow([c, cls_map[c]])\n",
    "        else:\n",
    "            # if you see many misses here, your folders may not be named 'subtype0/1/2'\n",
    "            pass\n",
    "\n",
    "print(\"Wrote dataset.json, splits_final.json, classification_labels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1501568-3b84-4289-9517-7ac312cc9446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Wrote v2 dataset.json at: D:/nnunet_with_classification/data/nnUNet_raw/Dataset777_M31Quiz/dataset.json\n",
      "numTraining: 288\n"
     ]
    }
   ],
   "source": [
    "import json, glob, os, pathlib\n",
    "\n",
    "DSID = 777\n",
    "DSNAME = f\"Dataset{DSID:03d}_M31Quiz\"\n",
    "RAW   = os.environ[\"nnUNet_raw\"]\n",
    "DSROOT = f\"{RAW}/{DSNAME}\"\n",
    "lblTr = f\"{DSROOT}/labelsTr\"\n",
    "\n",
    "dataset_v2 = {\n",
    "    \"channel_names\": { \"0\": \"CT\" },               # required in v2\n",
    "    \"labels\": { \"background\": 0, \"pancreas\": 1, \"lesion\": 2 },  # your classes\n",
    "    \"numTraining\": len(glob.glob(os.path.join(lblTr, \"*.nii.gz\"))),\n",
    "    \"file_ending\": \".nii.gz\"\n",
    "}\n",
    "with open(f\"{DSROOT}/dataset.json\", \"w\") as f:\n",
    "    json.dump(dataset_v2, f, indent=2)\n",
    "\n",
    "print(\"✅ Wrote v2 dataset.json at:\", f\"{DSROOT}/dataset.json\")\n",
    "print(\"numTraining:\", dataset_v2[\"numTraining\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "120217f3-ddd3-417f-b7fd-67c08ebebb1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Masks needing fix: 214\n",
      "   quiz_0_060.nii.gz unique: [0.         1.00001526 2.        ]\n",
      "   quiz_0_066.nii.gz unique: [0.         1.00001526 2.        ]\n",
      "   quiz_0_077.nii.gz unique: [0.         1.00001526 2.        ]\n",
      "   quiz_0_117.nii.gz unique: [0.         1.00001526 2.        ]\n",
      "   quiz_0_126.nii.gz unique: [0.         1.00001526 2.        ]\n",
      "   quiz_0_139.nii.gz unique: [0.         1.00001526 2.        ]\n",
      "   quiz_0_145.nii.gz unique: [0.         1.00001526 2.        ]\n",
      "   quiz_0_150.nii.gz unique: [0.         1.00001526 2.        ]\n",
      "   quiz_0_159.nii.gz unique: [0.         1.00001526 2.        ]\n",
      "   quiz_0_160.nii.gz unique: [0.         1.00001526 2.        ]\n",
      "Remaining masks with non-{0,1,2} labels: 0\n"
     ]
    }
   ],
   "source": [
    "import nibabel as nib, numpy as np, glob, os, pathlib\n",
    "\n",
    "DSID = 777\n",
    "DSNAME = f\"Dataset{DSID:03d}_M31Quiz\"\n",
    "lblTr = os.path.join(os.environ[\"nnUNet_raw\"], DSNAME, \"labelsTr\")\n",
    "\n",
    "bad = []\n",
    "for p in sorted(glob.glob(os.path.join(lblTr, \"*.nii.gz\"))):\n",
    "    img = nib.load(p)\n",
    "    arr = img.get_fdata()  # floats possible\n",
    "    uniq = np.unique(arr)\n",
    "    if not np.all(np.isin(uniq, [0,1,2])):\n",
    "        bad.append((p, uniq))\n",
    "\n",
    "print(\"Masks needing fix:\", len(bad))\n",
    "for p, uniq in bad[:10]:\n",
    "    print(\"  \", pathlib.Path(p).name, \"unique:\", uniq[:10])\n",
    "\n",
    "# Fix: round and clip to {0,1,2}, write as uint8\n",
    "for p, uniq in bad:\n",
    "    img = nib.load(p)\n",
    "    arr = img.get_fdata()\n",
    "    arr = np.rint(arr)           # round to nearest integer\n",
    "    arr = np.clip(arr, 0, 2)     # enforce label set\n",
    "    arr = arr.astype(np.uint8)\n",
    "\n",
    "    hdr = img.header.copy()\n",
    "    hdr.set_data_dtype(np.uint8)\n",
    "    # avoid unintended scaling\n",
    "    hdr[\"scl_slope\"] = 1\n",
    "    hdr[\"scl_inter\"] = 0\n",
    "\n",
    "    fixed = nib.Nifti1Image(arr, img.affine, hdr)\n",
    "    nib.save(fixed, p)\n",
    "\n",
    "# Sanity check after fix\n",
    "remaining = []\n",
    "for p in sorted(glob.glob(os.path.join(lblTr, \"*.nii.gz\"))):\n",
    "    arr = nib.load(p).get_fdata()\n",
    "    uniq = np.unique(arr)\n",
    "    if not np.all(np.isin(uniq, [0,1,2])):\n",
    "        remaining.append((p, uniq))\n",
    "print(\"Remaining masks with non-{0,1,2} labels:\", len(remaining))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4b5c41-bdc0-4955-9ec2-026fd80a8887",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nnUNetv2_plan_and_preprocess -d 777 -c 3d_fullres --verify_dataset_integrity -pl nnUNetPlannerResEncM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6409a5b-3511-42e0-8ac7-7f9dff1a2fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nnUNetv2_train 777 3d_fullres 0 -tr NNUNet -p nnUNetResEncUNetMPlans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c73bcb-1d70-46bd-bb39-a9dfa1140758",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (nnunet_new)",
   "language": "python",
   "name": "nnunet_new"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
