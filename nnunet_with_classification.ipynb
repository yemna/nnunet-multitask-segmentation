{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8282a088-298f-4d8b-ba24-5789aa440bf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch: 2.5.1+cu121\n",
      "CUDA available: True\n",
      "nnU-Net v2 imported successfully!\n",
      "nnunetv2 location: C:\\Users\\User\\anaconda3\\envs\\nnunet_new\\Lib\\site-packages\\nnunetv2\\__init__.py\n"
     ]
    }
   ],
   "source": [
    "import torch, nnunetv2\n",
    "print(\"Torch:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"nnU-Net v2 imported successfully!\")\n",
    "\n",
    "# Test that you can access nnunetv2 modules\n",
    "print(\"nnunetv2 location:\", nnunetv2.__file__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "63eaeca7-0cf7-4026-9ccd-24e5e552a7d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch: 2.5.1+cu121 | CUDA: 12.1\n",
      "nnU-Net v2: imported successfully!\n",
      "nnU-Net directories created at: D:/nnunet_with_classification/data\n"
     ]
    }
   ],
   "source": [
    "import os, nnunetv2, torch\n",
    "\n",
    "# Work directories - updated for your local setup\n",
    "BASE = \"D:/nnunet_with_classification/data\"\n",
    "RAW  = f\"{BASE}/nnUNet_raw\"\n",
    "PREP = f\"{BASE}/nnUNet_preprocessed\"\n",
    "RES  = f\"{BASE}/nnUNet_results\"\n",
    "\n",
    "# Create nnU-Net directories\n",
    "os.makedirs(RAW, exist_ok=True)\n",
    "os.makedirs(PREP, exist_ok=True)\n",
    "os.makedirs(RES, exist_ok=True)\n",
    "\n",
    "# Set environment variables\n",
    "os.environ[\"nnUNet_raw\"] = RAW\n",
    "os.environ[\"nnUNet_preprocessed\"] = PREP\n",
    "os.environ[\"nnUNet_results\"] = RES\n",
    "\n",
    "print(\"Torch:\", torch.__version__, \"| CUDA:\", torch.version.cuda)\n",
    "print(\"nnU-Net v2: imported successfully!\")\n",
    "print(f\"nnU-Net directories created at: {BASE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3405a90-353b-41cf-99f6-4659c37083b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob, pathlib, shutil, re, json, csv\n",
    "\n",
    "# >>>>>>>>>>>> UPDATE THIS PATH <<<<<<<<<<<<\n",
    "SRC = \"D:/nnunet_with_classification/data\"\n",
    "\n",
    "DSID = 777\n",
    "DSNAME = f\"Dataset{DSID:03d}_M31Quiz\"\n",
    "RAW  = os.environ[\"nnUNet_raw\"]\n",
    "PREP = os.environ[\"nnUNet_preprocessed\"]\n",
    "DSROOT = f\"{RAW}/{DSNAME}\"\n",
    "imgTr = f\"{DSROOT}/imagesTr\"; lblTr = f\"{DSROOT}/labelsTr\"; imgTs = f\"{DSROOT}/imagesTs\"\n",
    "for d in (imgTr, lblTr, imgTs): os.makedirs(d, exist_ok=True)\n",
    "\n",
    "def stem(p): return pathlib.Path(p).name.replace(\".nii.gz\",\"\")\n",
    "sub_regex = re.compile(r\"subtype\\s*([012])\", re.IGNORECASE)\n",
    "\n",
    "def find_split(name):\n",
    "    # case-insensitive split folder lookup\n",
    "    for cand in os.listdir(SRC):\n",
    "        if cand.lower() == name:\n",
    "            p = os.path.join(SRC, cand)\n",
    "            if os.path.isdir(p): return p\n",
    "    return None\n",
    "\n",
    "train_dir = find_split(\"train\")\n",
    "val_dir   = find_split(\"validation\")\n",
    "test_dir  = find_split(\"test\")\n",
    "assert train_dir and val_dir and test_dir, f\"Could not find train/validation/test under {SRC}\"\n",
    "\n",
    "def ingest_split(split_dir, cls_map):\n",
    "    imgs = glob.glob(os.path.join(split_dir, \"**\", \"*_0000.nii.gz\"), recursive=True)\n",
    "    used = 0\n",
    "    for img in sorted(imgs):\n",
    "        case = stem(img).replace(\"_0000\",\"\")\n",
    "        msk  = img.replace(\"_0000.nii.gz\",\".nii.gz\")\n",
    "        if not os.path.exists(msk):\n",
    "            continue\n",
    "        shutil.copy(img, f\"{imgTr}/{case}_0000.nii.gz\")\n",
    "        shutil.copy(msk, f\"{lblTr}/{case}.nii.gz\")\n",
    "        used += 1\n",
    "        # infer subtype from folder names (expects 'subtype0/1/2')\n",
    "        sub_idx = None\n",
    "        for part in pathlib.Path(img).parts:\n",
    "            m = sub_regex.search(part)\n",
    "            if m:\n",
    "                sub_idx = int(m.group(1)); break\n",
    "        if sub_idx is not None:\n",
    "            cls_map[case] = sub_idx\n",
    "    return used\n",
    "\n",
    "cls_map = {}\n",
    "n_tr = ingest_split(train_dir, cls_map)\n",
    "n_va = ingest_split(val_dir,   cls_map)\n",
    "\n",
    "# test images\n",
    "for img in sorted(glob.glob(os.path.join(test_dir, \"**\", \"*_0000.nii.gz\"), recursive=True)):\n",
    "    case = stem(img).replace(\"_0000\",\"\")\n",
    "    shutil.copy(img, f\"{imgTs}/{case}_0000.nii.gz\")\n",
    "\n",
    "print(\"imagesTr:\", len(glob.glob(f\"{imgTr}/*_0000.nii.gz\")))\n",
    "print(\"labelsTr:\", len(glob.glob(f\"{lblTr}/*.nii.gz\")))\n",
    "print(\"imagesTs:\", len(glob.glob(f\"{imgTs}/*_0000.nii.gz\")))\n",
    "print(\"Mapped classification labels:\", len(cls_map))\n",
    "\n",
    "# dataset.json\n",
    "dataset_json = {\n",
    "  \"name\": DSNAME,\n",
    "  \"tensorImageSize\": \"3D\",\n",
    "  \"modality\": {\"0\": \"CT\"},\n",
    "  \"labels\": {\"background\": 0, \"pancreas\": 1, \"lesion\": 2},\n",
    "  \"numTraining\": len(glob.glob(f\"{lblTr}/*.nii.gz\")),\n",
    "  \"numTest\": len(glob.glob(f\"{imgTs}/*_0000.nii.gz\")),\n",
    "  \"training\": [{\"image\": f\"./imagesTr/{stem(i)}.nii.gz\",\n",
    "                \"label\": f\"./labelsTr/{stem(i).replace('_0000','')}.nii.gz\"}\n",
    "               for i in sorted(glob.glob(f\"{imgTr}/*_0000.nii.gz\"))],\n",
    "  \"test\": [f\"./imagesTs/{stem(i)}.nii.gz\" for i in sorted(glob.glob(f\"{imgTs}/*_0000.nii.gz\"))]\n",
    "}\n",
    "os.makedirs(DSROOT, exist_ok=True)\n",
    "with open(f\"{DSROOT}/dataset.json\",\"w\") as f: json.dump(dataset_json, f, indent=2)\n",
    "\n",
    "# splits_final.json (use original validation as nnU-Net val)\n",
    "val_cases = {stem(p).replace(\"_0000\",\"\") for p in glob.glob(os.path.join(val_dir, \"**\", \"*_0000.nii.gz\"), recursive=True)}\n",
    "all_cases = sorted([stem(p).replace(\"_0000\",\"\") for p in glob.glob(f\"{imgTr}/*_0000.nii.gz\")])\n",
    "train_cases = [c for c in all_cases if c not in val_cases]\n",
    "spdir = f\"{PREP}/{DSNAME}\"\n",
    "os.makedirs(spdir, exist_ok=True)\n",
    "with open(f\"{spdir}/splits_final.json\",\"w\") as f:\n",
    "    json.dump([{\"train\": train_cases, \"val\": sorted(list(val_cases))}], f, indent=2)\n",
    "\n",
    "# classification_labels.csv\n",
    "csv_path = f\"{spdir}/classification_labels.csv\"\n",
    "with open(csv_path, \"w\", newline=\"\") as f:\n",
    "    w = csv.writer(f)\n",
    "    for c in all_cases:\n",
    "        if c in cls_map:\n",
    "            w.writerow([c, cls_map[c]])\n",
    "        else:\n",
    "            # if you see many misses here, your folders may not be named 'subtype0/1/2'\n",
    "            pass\n",
    "\n",
    "print(\"Wrote dataset.json, splits_final.json, classification_labels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1501568-3b84-4289-9517-7ac312cc9446",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, glob, os, pathlib\n",
    "\n",
    "DSID = 777\n",
    "DSNAME = f\"Dataset{DSID:03d}_M31Quiz\"\n",
    "RAW   = os.environ[\"nnUNet_raw\"]\n",
    "DSROOT = f\"{RAW}/{DSNAME}\"\n",
    "lblTr = f\"{DSROOT}/labelsTr\"\n",
    "\n",
    "dataset_v2 = {\n",
    "    \"channel_names\": { \"0\": \"CT\" },               # required in v2\n",
    "    \"labels\": { \"background\": 0, \"pancreas\": 1, \"lesion\": 2 },  # your classes\n",
    "    \"numTraining\": len(glob.glob(os.path.join(lblTr, \"*.nii.gz\"))),\n",
    "    \"file_ending\": \".nii.gz\"\n",
    "}\n",
    "with open(f\"{DSROOT}/dataset.json\", \"w\") as f:\n",
    "    json.dump(dataset_v2, f, indent=2)\n",
    "\n",
    "print(\"✅ Wrote v2 dataset.json at:\", f\"{DSROOT}/dataset.json\")\n",
    "print(\"numTraining:\", dataset_v2[\"numTraining\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120217f3-ddd3-417f-b7fd-67c08ebebb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib, numpy as np, glob, os, pathlib\n",
    "\n",
    "DSID = 777\n",
    "DSNAME = f\"Dataset{DSID:03d}_M31Quiz\"\n",
    "lblTr = os.path.join(os.environ[\"nnUNet_raw\"], DSNAME, \"labelsTr\")\n",
    "\n",
    "bad = []\n",
    "for p in sorted(glob.glob(os.path.join(lblTr, \"*.nii.gz\"))):\n",
    "    img = nib.load(p)\n",
    "    arr = img.get_fdata()  # floats possible\n",
    "    uniq = np.unique(arr)\n",
    "    if not np.all(np.isin(uniq, [0,1,2])):\n",
    "        bad.append((p, uniq))\n",
    "\n",
    "print(\"Masks needing fix:\", len(bad))\n",
    "for p, uniq in bad[:10]:\n",
    "    print(\"  \", pathlib.Path(p).name, \"unique:\", uniq[:10])\n",
    "\n",
    "# Fix: round and clip to {0,1,2}, write as uint8\n",
    "for p, uniq in bad:\n",
    "    img = nib.load(p)\n",
    "    arr = img.get_fdata()\n",
    "    arr = np.rint(arr)           # round to nearest integer\n",
    "    arr = np.clip(arr, 0, 2)     # enforce label set\n",
    "    arr = arr.astype(np.uint8)\n",
    "\n",
    "    hdr = img.header.copy()\n",
    "    hdr.set_data_dtype(np.uint8)\n",
    "    # avoid unintended scaling\n",
    "    hdr[\"scl_slope\"] = 1\n",
    "    hdr[\"scl_inter\"] = 0\n",
    "\n",
    "    fixed = nib.Nifti1Image(arr, img.affine, hdr)\n",
    "    nib.save(fixed, p)\n",
    "\n",
    "# Sanity check after fix\n",
    "remaining = []\n",
    "for p in sorted(glob.glob(os.path.join(lblTr, \"*.nii.gz\"))):\n",
    "    arr = nib.load(p).get_fdata()\n",
    "    uniq = np.unique(arr)\n",
    "    if not np.all(np.isin(uniq, [0,1,2])):\n",
    "        remaining.append((p, uniq))\n",
    "print(\"Remaining masks with non-{0,1,2} labels:\", len(remaining))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4b5c41-bdc0-4955-9ec2-026fd80a8887",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nnUNetv2_plan_and_preprocess -d 777 -c 3d_fullres --verify_dataset_integrity -pl nnUNetPlannerResEncM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09930477-4b85-4ae5-ac1a-02fa99b0dd1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nnUNetv2_train 777 3d_fullres 0 -tr nnUNetTrainerWithClassification -p nnUNetResEncUNetMPlans --c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1687c63-cf69-43e4-b440-febeb644e55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to get inference on validation for segmentation\n",
    "\n",
    "!python scripts/inference.py \\\n",
    "  --model_dir \"D:/nnunet_with_classification/data/nnUNet_results/Dataset777_M31Quiz/nnUNetTrainerWithClassification__nnUNetResEncUNetMPlans__3d_fullres\" \\\n",
    "  --input_dir \"D:/nnunet_with_classification/data/validation_flat\" \\\n",
    "  --output_dir \"D:/nnunet_with_classification/data/predication_seg_final_best\" \\\n",
    "  --fold 0 \\\n",
    "  --checkpoint checkpoint_best.pth \\\n",
    "  --num_classes 3 \\\n",
    "  --no-tta \\\n",
    "  --preproc_workers 1 \\\n",
    "  --export_workers 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f236fef5-00cf-40d2-8fba-36571e233ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to get inference on validation for classifictaion\n",
    "\n",
    "!python scripts/inference_probs_both.py \\\n",
    "  --model_dir \"D:/nnunet_with_classification/data/nnUNet_results/Dataset777_M31Quiz/nnUNetTrainerWithClassification__nnUNetResEncUNetMPlans__3d_fullres\" \\\n",
    "  --input_dir \"D:/nnunet_with_classification/data/validation_flat\" \\\n",
    "  --output_dir \"D:/nnunet_with_classification/data/predication_classification_final_both_probs\" \\\n",
    "  --fold 0 \\\n",
    "  --checkpoint checkpoint_best_classification.pth \\\n",
    "  --num_classes 3 \\\n",
    "  --no-tta \\\n",
    "  --preproc_workers 1 \\\n",
    "  --export_workers 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4377ecc1-623b-4277-909d-b9d75a544e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(r'D:\\nnunet_with_classification\\scripts')\n",
    "import balanced_tile_to_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a675715-b99f-44a3-bbbf-497b9a21efbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting D:\\nnunet_with_classification\\data\\predication_classification_final_both_probs\\classification_tile_probs.jsonl using class_balanced method\n",
      "Saved 36 predictions to D:\\nnunet_with_classification\\data\\predication_classification_final_both_probs\\balanced_predictions.csv\n",
      "Class distribution:\n",
      "   Class 0: 7 cases (19.4%) - Avg conf: 0.498\n",
      "   Class 1: 27 cases (75.0%) - Avg conf: 0.413\n",
      "   Class 2: 2 cases (5.6%) - Avg conf: 0.426\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case</th>\n",
       "      <th>pred_class</th>\n",
       "      <th>Confidence</th>\n",
       "      <th>Method</th>\n",
       "      <th>Prob_Class_0</th>\n",
       "      <th>Prob_Class_1</th>\n",
       "      <th>Prob_Class_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>quiz_0_168.nii.gz</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4182</td>\n",
       "      <td>class_balanced</td>\n",
       "      <td>0.2742</td>\n",
       "      <td>0.4182</td>\n",
       "      <td>0.3076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>quiz_0_171.nii.gz</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3988</td>\n",
       "      <td>class_balanced</td>\n",
       "      <td>0.3565</td>\n",
       "      <td>0.3988</td>\n",
       "      <td>0.2446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>quiz_0_174.nii.gz</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6572</td>\n",
       "      <td>class_balanced</td>\n",
       "      <td>0.6572</td>\n",
       "      <td>0.2272</td>\n",
       "      <td>0.1156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>quiz_0_184.nii.gz</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4284</td>\n",
       "      <td>class_balanced</td>\n",
       "      <td>0.2385</td>\n",
       "      <td>0.4284</td>\n",
       "      <td>0.3330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>quiz_0_187.nii.gz</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4377</td>\n",
       "      <td>class_balanced</td>\n",
       "      <td>0.3217</td>\n",
       "      <td>0.4377</td>\n",
       "      <td>0.2406</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                case  pred_class Confidence          Method Prob_Class_0  \\\n",
       "0  quiz_0_168.nii.gz           1     0.4182  class_balanced       0.2742   \n",
       "1  quiz_0_171.nii.gz           1     0.3988  class_balanced       0.3565   \n",
       "2  quiz_0_174.nii.gz           0     0.6572  class_balanced       0.6572   \n",
       "3  quiz_0_184.nii.gz           1     0.4284  class_balanced       0.2385   \n",
       "4  quiz_0_187.nii.gz           1     0.4377  class_balanced       0.3217   \n",
       "\n",
       "  Prob_Class_1 Prob_Class_2  \n",
       "0       0.4182       0.3076  \n",
       "1       0.3988       0.2446  \n",
       "2       0.2272       0.1156  \n",
       "3       0.4284       0.3330  \n",
       "4       0.4377       0.2406  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jsonl_file = r\"D:\\nnunet_with_classification\\data\\predication_classification_final_both_probs\\classification_tile_probs.jsonl\"\n",
    "output_file = r\"D:\\nnunet_with_classification\\data\\predication_classification_final_both_probs\\balanced_predictions.csv\"\n",
    "# This gives equal weight to each predicted class, not each tile\n",
    "df = balanced_tile_to_csv.convert_tiles_balanced(\n",
    "    jsonl_file, \n",
    "    output_file, \n",
    "    method='class_balanced'\n",
    ")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "299fb0fa-f19f-42c1-a4db-f174ed2ccc7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Testing class_balanced ---\n",
      "Converting D:\\nnunet_with_classification\\data\\predication_classification_final_both_probs\\classification_tile_probs.jsonl using class_balanced method\n",
      "Saved 36 predictions to D:\\nnunet_with_classification\\data\\predication_classification_final_both_probs\\method_comparison\\predictions_class_balanced.csv\n",
      "Class distribution:\n",
      "   Class 0: 7 cases (19.4%) - Avg conf: 0.498\n",
      "   Class 1: 27 cases (75.0%) - Avg conf: 0.413\n",
      "   Class 2: 2 cases (5.6%) - Avg conf: 0.426\n",
      "\n",
      "--- Testing minority_boost ---\n",
      "Converting D:\\nnunet_with_classification\\data\\predication_classification_final_both_probs\\classification_tile_probs.jsonl using minority_boost method\n",
      "Saved 36 predictions to D:\\nnunet_with_classification\\data\\predication_classification_final_both_probs\\method_comparison\\predictions_minority_boost.csv\n",
      "Class distribution:\n",
      "   Class 0: 7 cases (19.4%) - Avg conf: 0.572\n",
      "   Class 1: 26 cases (72.2%) - Avg conf: 0.513\n",
      "   Class 2: 3 cases (8.3%) - Avg conf: 0.514\n",
      "\n",
      "--- Testing entropy_threshold ---\n",
      "Converting D:\\nnunet_with_classification\\data\\predication_classification_final_both_probs\\classification_tile_probs.jsonl using entropy_threshold method\n",
      "Saved 36 predictions to D:\\nnunet_with_classification\\data\\predication_classification_final_both_probs\\method_comparison\\predictions_entropy_threshold.csv\n",
      "Class distribution:\n",
      "   Class 0: 7 cases (19.4%) - Avg conf: 0.498\n",
      "   Class 1: 28 cases (77.8%) - Avg conf: 0.412\n",
      "   Class 2: 1 cases (2.8%) - Avg conf: 0.485\n"
     ]
    }
   ],
   "source": [
    "# Compare with other methods\n",
    "results = balanced_tile_to_csv.compare_methods(\n",
    "    jsonl_file, \n",
    "    r\"D:\\nnunet_with_classification\\data\\predication_classification_final_both_probs\\method_comparison\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f7fba2d3-0394-4881-97f1-8bdfcc9a6664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Checking paths...\n",
      "GT segmentation dir:          D:/nnunet_with_classification/data/nnUNet_raw/Dataset777_M31Quiz/labelsTr   -> True\n",
      "Predicted segmentation dir:   D:/nnunet_with_classification/data/predication_seg_final_best -> True\n",
      "GT classification CSV:        D:/nnunet_with_classification/data/validation_labels.csv   -> True\n",
      "Predicted classification CSV: D:/nnunet_with_classification/data/predication_classification_final_both_probs/method_comparison/predictions_class_balanced.csv -> True\n",
      "\n",
      "📊 Computing segmentation metrics...\n",
      "Pancreas DSC (mean): 0.9029\n",
      "Lesion   DSC (mean): 0.5811\n",
      "\n",
      "🎯 Computing classification metrics...\n",
      "Using GT columns: case='case', label='label'\n",
      "Using prediction case column: 'case'\n",
      "\n",
      "Found 288 GT labels and 36 predictions\n",
      "Matched 36 cases for evaluation\n",
      "\n",
      "Overall Accuracy: 0.5278\n",
      "Macro F1:         0.4425\n",
      "Micro F1:         0.5278\n",
      "Weighted F1:      0.4668\n",
      "\n",
      "📈 Per-Class Classification Metrics:\n",
      "------------------------------------------------------------\n",
      "Class      Precision    Recall     F1-Score   Support \n",
      "------------------------------------------------------------\n",
      "Subtype 0  0.4286       0.3333     0.3750     9       \n",
      "Subtype 1  0.5185       0.9333     0.6667     15      \n",
      "Subtype 2  1.0000       0.1667     0.2857     12      \n",
      "\n",
      "🎯 Confusion Matrix:\n",
      "----------------------------------------\n",
      "Predicted ->    0    1    2\n",
      "True ↓\n",
      "      0         3    6    0\n",
      "      1         1   14    0\n",
      "      2         3    7    2\n",
      "\n",
      "==================================================\n",
      "                    SUMMARY\n",
      "==================================================\n",
      "Whole Pancreas DSC: 0.9029\n",
      "Lesion DSC:         0.5811\n",
      "Classification Acc: 0.5278\n",
      "Macro F1:           0.4425\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Fixed evaluation script - handles .nii.gz extension in CSV\n",
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from sklearn.metrics import f1_score, classification_report, precision_recall_fscore_support, confusion_matrix\n",
    "\n",
    "# Validation cases (base names without extension)\n",
    "validation_cases = [\n",
    "    \"quiz_0_168\", \"quiz_0_171\", \"quiz_0_174\", \"quiz_0_184\", \"quiz_0_187\", \n",
    "    \"quiz_0_189\", \"quiz_0_244\", \"quiz_0_253\", \"quiz_0_254\", \"quiz_1_090\",\n",
    "    \"quiz_1_093\", \"quiz_1_094\", \"quiz_1_154\", \"quiz_1_158\", \"quiz_1_164\",\n",
    "    \"quiz_1_166\", \"quiz_1_211\", \"quiz_1_213\", \"quiz_1_221\", \"quiz_1_227\",\n",
    "    \"quiz_1_231\", \"quiz_1_242\", \"quiz_1_331\", \"quiz_1_335\", \"quiz_2_074\",\n",
    "    \"quiz_2_080\", \"quiz_2_084\", \"quiz_2_085\", \"quiz_2_088\", \"quiz_2_089\",\n",
    "    \"quiz_2_098\", \"quiz_2_191\", \"quiz_2_241\", \"quiz_2_364\", \"quiz_2_377\",\n",
    "    \"quiz_2_379\"\n",
    "]\n",
    "\n",
    "# Paths\n",
    "gt_seg_dir   = f\"{os.environ['nnUNet_raw']}/Dataset777_M31Quiz/labelsTr\"\n",
    "pred_seg_dir = \"D:/nnunet_with_classification/data/predication_seg_final_best\"\n",
    "gt_cls_csv   = \"D:/nnunet_with_classification/data/validation_labels.csv\"\n",
    "pred_cls_csv = \"D:/nnunet_with_classification/data/predication_classification_final_both_probs/method_comparison/predictions_class_balanced.csv\"\n",
    "\n",
    "def clean_case_name(case_name):\n",
    "    \"\"\"Remove .nii.gz extension and strip whitespace\"\"\"\n",
    "    return str(case_name).strip().replace('.nii.gz', '')\n",
    "\n",
    "def dice_score(y_true, y_pred):\n",
    "    \"\"\"Compute Dice Similarity Coefficient\"\"\"\n",
    "    intersection = np.sum(y_true * y_pred)\n",
    "    total = np.sum(y_true) + np.sum(y_pred)\n",
    "    return (2.0 * intersection) / total if total > 0 else 1.0\n",
    "\n",
    "# Check paths\n",
    "print(\"🔍 Checking paths...\")\n",
    "print(f\"GT segmentation dir:          {gt_seg_dir}   -> {os.path.exists(gt_seg_dir)}\")\n",
    "print(f\"Predicted segmentation dir:   {pred_seg_dir} -> {os.path.exists(pred_seg_dir)}\")\n",
    "print(f\"GT classification CSV:        {gt_cls_csv}   -> {os.path.exists(gt_cls_csv)}\")\n",
    "print(f\"Predicted classification CSV: {pred_cls_csv} -> {os.path.exists(pred_cls_csv)}\")\n",
    "\n",
    "# Segmentation metrics\n",
    "print(\"\\n📊 Computing segmentation metrics...\")\n",
    "pancreas_dices, lesion_dices, missing_files = [], [], []\n",
    "\n",
    "for case in validation_cases:\n",
    "    gt_file   = f\"{gt_seg_dir}/{case}.nii.gz\"\n",
    "    pred_file = f\"{pred_seg_dir}/{case}.nii.gz\"\n",
    "    \n",
    "    if os.path.exists(gt_file) and os.path.exists(pred_file):\n",
    "        try:\n",
    "            gt   = nib.load(gt_file).get_fdata()\n",
    "            pred = nib.load(pred_file).get_fdata()\n",
    "            \n",
    "            # Whole pancreas (>0)\n",
    "            gt_pancreas   = (gt  > 0).astype(np.uint8)\n",
    "            pred_pancreas = (pred > 0).astype(np.uint8)\n",
    "            pancreas_dices.append(dice_score(gt_pancreas, pred_pancreas))\n",
    "            \n",
    "            # Lesion (== 2)\n",
    "            gt_lesion   = (gt  == 2).astype(np.uint8)\n",
    "            pred_lesion = (pred == 2).astype(np.uint8)\n",
    "            lesion_dices.append(dice_score(gt_lesion, pred_lesion))\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {case}: {e}\")\n",
    "            missing_files.append(case)\n",
    "    else:\n",
    "        missing_files.append(case)\n",
    "\n",
    "if pancreas_dices:\n",
    "    whole_pancreas_dsc = float(np.mean(pancreas_dices))\n",
    "    lesion_dsc         = float(np.mean(lesion_dices))\n",
    "    print(f\"Pancreas DSC (mean): {whole_pancreas_dsc:.4f}\")\n",
    "    print(f\"Lesion   DSC (mean): {lesion_dsc:.4f}\")\n",
    "else:\n",
    "    whole_pancreas_dsc = 0.0\n",
    "    lesion_dsc         = 0.0\n",
    "    print(\"No matched segmentation files found.\")\n",
    "\n",
    "# Classification metrics - FIXED to handle .nii.gz extensions\n",
    "print(\"\\n🎯 Computing classification metrics...\")\n",
    "\n",
    "# Load GT labels (handle different column names)\n",
    "gt_labels = {}\n",
    "if os.path.exists(gt_cls_csv):\n",
    "    with open(gt_cls_csv, 'r', newline='', encoding='utf-8') as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        \n",
    "        # Try different possible column names\n",
    "        case_col = None\n",
    "        label_col = None\n",
    "        \n",
    "        for col in ['case', 'Cases', 'Names', 'Case', 'names']:\n",
    "            if col in reader.fieldnames:\n",
    "                case_col = col\n",
    "                break\n",
    "        \n",
    "        for col in ['label', 'Label', 'Subtype', 'subtype', 'pred_class']:\n",
    "            if col in reader.fieldnames:\n",
    "                label_col = col\n",
    "                break\n",
    "        \n",
    "        if not case_col:\n",
    "            case_col = reader.fieldnames[0]  # Use first column\n",
    "        if not label_col:\n",
    "            label_col = reader.fieldnames[1]  # Use second column\n",
    "        \n",
    "        print(f\"Using GT columns: case='{case_col}', label='{label_col}'\")\n",
    "        \n",
    "        # Reset file pointer\n",
    "        f.seek(0)\n",
    "        reader = csv.DictReader(f)\n",
    "        \n",
    "        for row in reader:\n",
    "            case_name = clean_case_name(row[case_col])\n",
    "            gt_labels[case_name] = int(row[label_col])\n",
    "\n",
    "# Load prediction labels\n",
    "pred_labels = {}\n",
    "if os.path.exists(pred_cls_csv):\n",
    "    with open(pred_cls_csv, 'r', newline='', encoding='utf-8') as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        \n",
    "        # Try different possible column names\n",
    "        case_col = None\n",
    "        for col in ['case', 'Cases', 'Names', 'Case', 'names']:\n",
    "            if col in reader.fieldnames:\n",
    "                case_col = col\n",
    "                break\n",
    "        \n",
    "        if not case_col:\n",
    "            case_col = reader.fieldnames[0]  # Use first column\n",
    "        \n",
    "        print(f\"Using prediction case column: '{case_col}'\")\n",
    "        \n",
    "        # Check for pred_class column or probability columns\n",
    "        has_pred_class = 'pred_class' in reader.fieldnames\n",
    "        prob_cols = [c for c in reader.fieldnames if c.startswith('Prob_Class_')]\n",
    "        \n",
    "        for row in reader:\n",
    "            case_name = clean_case_name(row[case_col])\n",
    "            \n",
    "            if has_pred_class and row.get('pred_class', '') != '':\n",
    "                pred_labels[case_name] = int(row['pred_class'])\n",
    "            elif prob_cols:\n",
    "                probs = np.array([float(row[p]) for p in prob_cols], dtype=float)\n",
    "                pred_labels[case_name] = int(np.argmax(probs))\n",
    "\n",
    "print(f\"\\nFound {len(gt_labels)} GT labels and {len(pred_labels)} predictions\")\n",
    "\n",
    "# Match validation cases with GT and predictions\n",
    "val_gt, val_pred = [], []\n",
    "matched_cases = []\n",
    "\n",
    "for case in validation_cases:\n",
    "    if case in gt_labels and case in pred_labels:\n",
    "        val_gt.append(gt_labels[case])\n",
    "        val_pred.append(pred_labels[case])\n",
    "        matched_cases.append(case)\n",
    "\n",
    "print(f\"Matched {len(matched_cases)} cases for evaluation\")\n",
    "\n",
    "if val_gt and val_pred:\n",
    "    # Overall metrics\n",
    "    macro_f1 = f1_score(val_gt, val_pred, average='macro')\n",
    "    micro_f1 = f1_score(val_gt, val_pred, average='micro')\n",
    "    weighted_f1 = f1_score(val_gt, val_pred, average='weighted')\n",
    "    accuracy = np.mean(np.array(val_gt) == np.array(val_pred))\n",
    "    \n",
    "    print(f\"\\nOverall Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Macro F1:         {macro_f1:.4f}\")\n",
    "    print(f\"Micro F1:         {micro_f1:.4f}\")\n",
    "    print(f\"Weighted F1:      {weighted_f1:.4f}\")\n",
    "    \n",
    "    # Per-class metrics\n",
    "    precision, recall, f1, support = precision_recall_fscore_support(val_gt, val_pred, average=None, zero_division=0)\n",
    "    \n",
    "    print(\"\\n📈 Per-Class Classification Metrics:\")\n",
    "    print(\"-\" * 60)\n",
    "    print(f\"{'Class':<10} {'Precision':<12} {'Recall':<10} {'F1-Score':<10} {'Support':<8}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    class_names = ['Subtype 0', 'Subtype 1', 'Subtype 2']\n",
    "    for i, class_name in enumerate(class_names):\n",
    "        if i < len(precision):\n",
    "            print(f\"{class_name:<10} {precision[i]:<12.4f} {recall[i]:<10.4f} {f1[i]:<10.4f} {support[i]:<8}\")\n",
    "        else:\n",
    "            print(f\"{class_name:<10} {'0.0000':<12} {'0.0000':<10} {'0.0000':<10} {'0':<8}\")\n",
    "    \n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(val_gt, val_pred)\n",
    "    print(\"\\n🎯 Confusion Matrix:\")\n",
    "    print(\"-\" * 40)\n",
    "    print(\"Predicted ->\", end=\"\")\n",
    "    for i in range(3):\n",
    "        print(f\"  {i:>3}\", end=\"\")\n",
    "    print()\n",
    "    print(\"True ↓\")\n",
    "    for i in range(3):\n",
    "        print(f\"    {i:>3}     \", end=\"\")\n",
    "        for j in range(3):\n",
    "            if i < cm.shape[0] and j < cm.shape[1]:\n",
    "                print(f\"  {cm[i,j]:>3}\", end=\"\")\n",
    "            else:\n",
    "                print(f\"  {0:>3}\", end=\"\")\n",
    "        print()\n",
    "    \n",
    "else:\n",
    "    macro_f1 = 0.0\n",
    "    accuracy = 0.0\n",
    "    print(\"No overlapping classification cases found between GT and predictions.\")\n",
    "\n",
    "# Final summary\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"                    SUMMARY\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Whole Pancreas DSC: {whole_pancreas_dsc:.4f}\")\n",
    "print(f\"Lesion DSC:         {lesion_dsc:.4f}\")\n",
    "print(f\"Classification Acc: {accuracy:.4f}\")\n",
    "print(f\"Macro F1:           {macro_f1:.4f}\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "if missing_files:\n",
    "    print(f\"\\n⚠️  Missing seg files for {len(missing_files)} cases\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24cb58f6-5606-40aa-a018-0d8e6249373b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to get segmentation inference on test data\n",
    "\n",
    "!python scripts/inference.py \\\n",
    "  --model_dir \"D:/nnunet_with_classification/data/nnUNet_results/Dataset777_M31Quiz/nnUNetTrainerWithClassification__nnUNetResEncUNetMPlans__3d_fullres\" \\\n",
    "  --input_dir \"D:/nnunet_with_classification/data/nnUNet_raw/Dataset777_M31Quiz/imagesTs\" \\\n",
    "  --output_dir \"D:/nnunet_with_classification/data/new_test_label_predictions_segmentation_best\" \\\n",
    "  --fold 0 \\\n",
    "  --checkpoint checkpoint_best.pth \\\n",
    "  --num_classes 3 \\\n",
    "  --no-tta \\\n",
    "  --preproc_workers 1 \\\n",
    "  --export_workers 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5991e220-0124-4396-9320-5091a71f6680",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to get classification inference on test data\n",
    "\n",
    "\n",
    "!python scripts/inference_probs_both.py \\\n",
    "  --model_dir \"D:/nnunet_with_classification/data/nnUNet_results/Dataset777_M31Quiz/nnUNetTrainerWithClassification__nnUNetResEncUNetMPlans__3d_fullres\" \\\n",
    "  --input_dir \"D:/nnunet_with_classification/data/nnUNet_raw/Dataset777_M31Quiz/imagesTs\" \\\n",
    "  --output_dir \"D:/nnunet_with_classification/data/predication_classification_final_both_probs_test_data\" \\\n",
    "  --fold 0 \\\n",
    "  --checkpoint checkpoint_best_classification.pth \\\n",
    "  --num_classes 3 \\\n",
    "  --no-tta \\\n",
    "  --preproc_workers 1 \\\n",
    "  --export_workers 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b3935530-ba93-43fd-97f3-8be9bb3beca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(r'D:\\nnunet_with_classification\\scripts')\n",
    "import balanced_tile_to_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4694fa3c-35c9-4b0a-93af-8e9962c85f70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting D:\\nnunet_with_classification\\data\\predication_classification_final_both_probs_test_data\\classification_tile_probs.jsonl using class_balanced method\n",
      "Saved 72 predictions to D:\\nnunet_with_classification\\data\\predication_classification_final_both_probs_test_data\\balanced_predictions.csv\n",
      "Class distribution:\n",
      "   Class 0: 10 cases (13.9%) - Avg conf: 0.444\n",
      "   Class 1: 60 cases (83.3%) - Avg conf: 0.409\n",
      "   Class 2: 2 cases (2.8%) - Avg conf: 0.378\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case</th>\n",
       "      <th>pred_class</th>\n",
       "      <th>Confidence</th>\n",
       "      <th>Method</th>\n",
       "      <th>Prob_Class_0</th>\n",
       "      <th>Prob_Class_1</th>\n",
       "      <th>Prob_Class_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>quiz_037.nii.gz</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4145</td>\n",
       "      <td>class_balanced</td>\n",
       "      <td>0.2735</td>\n",
       "      <td>0.4145</td>\n",
       "      <td>0.3120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>quiz_045.nii.gz</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4261</td>\n",
       "      <td>class_balanced</td>\n",
       "      <td>0.3623</td>\n",
       "      <td>0.4261</td>\n",
       "      <td>0.2116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>quiz_047.nii.gz</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3917</td>\n",
       "      <td>class_balanced</td>\n",
       "      <td>0.3011</td>\n",
       "      <td>0.3917</td>\n",
       "      <td>0.3072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>quiz_048.nii.gz</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4071</td>\n",
       "      <td>class_balanced</td>\n",
       "      <td>0.2649</td>\n",
       "      <td>0.4071</td>\n",
       "      <td>0.3280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>quiz_052.nii.gz</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4028</td>\n",
       "      <td>class_balanced</td>\n",
       "      <td>0.2672</td>\n",
       "      <td>0.4028</td>\n",
       "      <td>0.3300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              case  pred_class Confidence          Method Prob_Class_0  \\\n",
       "0  quiz_037.nii.gz           1     0.4145  class_balanced       0.2735   \n",
       "1  quiz_045.nii.gz           1     0.4261  class_balanced       0.3623   \n",
       "2  quiz_047.nii.gz           1     0.3917  class_balanced       0.3011   \n",
       "3  quiz_048.nii.gz           1     0.4071  class_balanced       0.2649   \n",
       "4  quiz_052.nii.gz           1     0.4028  class_balanced       0.2672   \n",
       "\n",
       "  Prob_Class_1 Prob_Class_2  \n",
       "0       0.4145       0.3120  \n",
       "1       0.4261       0.2116  \n",
       "2       0.3917       0.3072  \n",
       "3       0.4071       0.3280  \n",
       "4       0.4028       0.3300  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jsonl_file = r\"D:\\nnunet_with_classification\\data\\predication_classification_final_both_probs_test_data\\classification_tile_probs.jsonl\"\n",
    "output_file = r\"D:\\nnunet_with_classification\\data\\predication_classification_final_both_probs_test_data\\balanced_predictions.csv\"\n",
    "# This gives equal weight to each predicted class, not each tile\n",
    "df = balanced_tile_to_csv.convert_tiles_balanced(\n",
    "    jsonl_file, \n",
    "    output_file, \n",
    "    method='class_balanced'\n",
    ")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d0c587-357e-4e2a-b198-d3c950b35244",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (nnunet_new)",
   "language": "python",
   "name": "nnunet_new"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
